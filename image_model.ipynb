{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport argparse\nimport torch\nimport torch.utils.data\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torchvision import datasets, transforms\nfrom torchvision.utils import save_image\nimport torchvision.models as models\nimport matplotlib\nimport matplotlib.image as image\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"file_path = '/kaggle/input/uw-cs480-fall20/'\nimage_path = '/kaggle/input/uw-cs480-fall20/suffled-images/shuffled-images/'\n\ndef load_data():\n    train_df = pd.read_csv(file_path + 'train.csv')\n    test_df = pd.read_csv(file_path + 'test.csv')\n    return train_df, test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, test_df = load_data()\ndata_size = len(train_df)\nprint(data_size)\n\n# remove free gifts\ntrain_df = train_df[train_df.category != 'Free Gifts']\ndata_size = len(train_df)\nprint(data_size)\n\ncategories = train_df.category.unique()\ncategory_d = {k: v for v, k in enumerate(categories)}\n\ngenders = train_df.gender.unique()\ngender_d = {k: v for v, k in enumerate(genders)}\n\nbaseColours = train_df.baseColour.unique()\nbaseColour_d = {k: v for v, k in enumerate(baseColours)}\n\nseasons = train_df.season.unique()\nseason_d = {k: v for v, k in enumerate(seasons)}\n\nusages = train_df.usage.unique()\nusage_d = {k: v for v, k in enumerate(usages)}\n\ndata_size = len(train_df)\n\n\n# training data\n\ntrain_df.replace(\n    {'category': category_d,\n     'gender': gender_d,\n     'baseColour': baseColour_d,\n     'season': season_d,\n     'usage': usage_d}\n    , inplace=True\n)\n\n# testing data\n\ntest_df.replace(\n    {'category': category_d,\n     'gender': gender_d,\n     'baseColour': baseColour_d,\n     'season': season_d,\n     'usage': usage_d}\n    , inplace=True\n)\n\npreprocess_training = transforms.Compose([\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\npreprocess_test = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n\nclass Image_Dataset(Dataset):\n\n    def __init__(self, id_target, folder=image_path, transform=preprocess_training):\n        self.id_target = id_target\n        self.folder = folder\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.id_target)\n\n    def __getitem__(self, idx):\n        #if torch.is_tensor(idx):\n        #    idx = idx.tolist()\n\n        img_name = self.folder + str(id_target[idx][0]) + '.jpg'\n        image = Image.open(img_name)\n\n        #if self.transform:\n        result = self.transform(image)\n\n        return result, id_target[idx][1]\n\n\nid_target = train_df[['id', 'category']].values\n\nsplits = np.array_split(id_target, 5)\n#training_data_size = (data_size//5) * 4\n\ntrain_data1 = np.concatenate(np.delete(splits, 4, 0))\nvalidation_data1 = splits[4]\n\ntrain_data2 = np.concatenate(np.delete(splits, 3, 0))\nvalidation_data2 = splits[3]\n\ntrain_data3 = np.concatenate(np.delete(splits, 2, 0))\nvalidation_data3 = splits[2]\n\ntrain_data4 = np.concatenate(np.delete(splits, 1, 0))\nvalidation_data4 = splits[1]\n\ntrain_data5 = np.concatenate(np.delete(splits, 0, 0))\nvalidation_data5 = splits[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# script parameters\nbatch_size = 64\nlog_interval = 100\n\n# run on GPU if possible\ncuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if cuda else \"cpu\")\n\n# create data loaders\nkwargs = {'num_workers': 2, 'pin_memory': True} if cuda else {}\n\n\ntrain1 = Image_Dataset(train_data1)\nvalidation1 = Image_Dataset(validation_data1)\n\ntrain2 = Image_Dataset(train_data2)\nvalidation2 = Image_Dataset(validation_data2)\n\ntrain3 = Image_Dataset(train_data3)\nvalidation3 = Image_Dataset(validation_data3)\n\ntrain4 = Image_Dataset(train_data4)\nvalidation4 = Image_Dataset(validation_data4)\n\ntrain5 = Image_Dataset(train_data5)\nvalidation5 = Image_Dataset(validation_data5)\n\n\ntrain_loader1 = DataLoader(train1, batch_size=batch_size, shuffle=True, **kwargs)\nvalidation_loader1 = DataLoader(validation1, batch_size=batch_size, shuffle=True, **kwargs)\n\ntrain_loader2 = DataLoader(train2, batch_size=batch_size, shuffle=True, **kwargs)\nvalidation_loader2 = DataLoader(validation2, batch_size=batch_size, shuffle=True, **kwargs)\n\ntrain_loader3 = DataLoader(train3, batch_size=batch_size, shuffle=True, **kwargs)\nvalidation_loader3 = DataLoader(validation3, batch_size=batch_size, shuffle=True, **kwargs)\n\ntrain_loader4 = DataLoader(train4, batch_size=batch_size, shuffle=True, **kwargs)\nvalidation_loader4 = DataLoader(validation4, batch_size=batch_size, shuffle=True, **kwargs)\n\ntrain_loader5 = DataLoader(train5, batch_size=batch_size, shuffle=True, **kwargs)\nvalidation_loader5 = DataLoader(validation5, batch_size=batch_size, shuffle=True, **kwargs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = 26\n\nassert(len(categories) == num_classes)\n\nmodel_image1 = models.resnet50(num_classes=num_classes).to(device)\nmodel_image2 = models.resnet50(num_classes=num_classes).to(device)\nmodel_image3 = models.resnet50(num_classes=num_classes).to(device)\nmodel_image4 = models.resnet50(num_classes=num_classes).to(device)\nmodel_image5 = models.resnet50(num_classes=num_classes).to(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loss Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion_image1 = nn.CrossEntropyLoss(reduction='sum')\ncriterion_image2 = nn.CrossEntropyLoss(reduction='sum')\ncriterion_image3 = nn.CrossEntropyLoss(reduction='sum')\ncriterion_image4 = nn.CrossEntropyLoss(reduction='sum')\ncriterion_image5 = nn.CrossEntropyLoss(reduction='sum')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Optimizers"},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer_image1 = optim.Adam(model_image1.parameters(), lr=1e-3)\noptimizer_image2 = optim.Adam(model_image2.parameters(), lr=1e-3)\noptimizer_image3 = optim.Adam(model_image3.parameters(), lr=1e-3)\noptimizer_image4 = optim.Adam(model_image4.parameters(), lr=1e-3)\noptimizer_image5 = optim.Adam(model_image5.parameters(), lr=1e-3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_train(epoch, model, optimizer, criterion_image, train_loader):\n    model.train()\n    total_loss = 0\n    for batch_idx, (images, targets) in enumerate(train_loader):\n        \n        images = images.to(device)\n        targets = targets.to(device)\n        optimizer.zero_grad()\n        recon_batch = model(images)\n        \n        loss = criterion_image(recon_batch, targets)\n        loss.backward()\n        total_loss += loss.item()\n        optimizer.step()\n        if batch_idx % log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(images), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader),\n                loss.item() / len(images)))\n\n    average_loss = total_loss / len(train_loader.dataset)\n    print('====> Epoch: {} Average loss: {:.4f}'.format(\n          epoch, average_loss))\n    return average_loss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_test(epoch, model, criterion_image, validation_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for _, (images, targets) in enumerate(validation_loader):\n            images = images.to(device)\n            targets = targets.to(device)\n            recon_batch = model(images)\n            test_loss += criterion_image(recon_batch, targets).item()\n            \n            preds = recon_batch.argmax(dim=1)#, keepdim=True)\n            correct += preds.eq(targets).sum().item()\n            \n\n    average_test_loss = test_loss / len(validation_loader.dataset)\n    test_accuracy = correct / len(validation_loader.dataset)\n    print('====> Validation loss: {:.4f}'.format(average_test_loss))\n    print('====> Validation accuracy: {:.2f}'.format(test_accuracy))\n    return average_test_loss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Main"},{"metadata":{},"cell_type":"markdown","source":"## Parameter"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train and test\n\naverage_train_losses = []\naverage_test_losses = []\n\nfor epoch in range(1, epochs + 1):\n    average_train_loss = image_train(epoch, model_image1, optimizer_image1, criterion_image1, train_loader1)\n    average_train_losses.append(average_train_loss)\n    average_test_loss = image_test(epoch, model_image1, criterion_image1, train_loader1)\n\n    # save model with best validation loss\n    if epoch == 1 or average_test_loss < min(average_test_losses):\n        torch.save(model_image1, 'image_classification_model1.pt')\n\n    average_test_losses.append(average_test_loss)\n    \n\n# Plot Training Losses\nplt.plot(average_train_losses)\nplt.title('Train Losses')\nplt.ylabel('Cross Entropy')\nplt.xlabel('Epoch #')\nplt.legend(['Train'], loc='upper right')\nplt.show()\n\n# Plot Testing Losses\nplt.plot(average_test_losses)\nplt.title('Test Losses')\nplt.ylabel('Cross Entropy')\nplt.xlabel('Epoch #')\nplt.legend(['Test'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model2"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train and test\n\naverage_train_losses = []\naverage_test_losses = []\n\nfor epoch in range(1, epochs + 1):\n    average_train_loss = image_train(epoch, model_image2, optimizer_image2, criterion_image2, train_loader2)\n    average_train_losses.append(average_train_loss)\n    average_test_loss = image_test(epoch, model_image2, criterion_image2, train_loader2)\n\n    # save model with best validation loss\n    if epoch == 1 or average_test_loss < min(average_test_losses):\n        torch.save(model_image2, 'image_classification_model2.pt')\n\n    average_test_losses.append(average_test_loss)\n    \n\n# Plot Training Losses\nplt.plot(average_train_losses)\nplt.title('Train Losses')\nplt.ylabel('Cross Entropy')\nplt.xlabel('Epoch #')\nplt.legend(['Train'], loc='upper right')\nplt.show()\n\n# Plot Testing Losses\nplt.plot(average_test_losses)\nplt.title('Test Losses')\nplt.ylabel('Cross Entropy')\nplt.xlabel('Epoch #')\nplt.legend(['Test'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model3"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train and test\n\naverage_train_losses = []\naverage_test_losses = []\n\nfor epoch in range(1, epochs + 1):\n    average_train_loss = image_train(epoch, model_image3, optimizer_image3, criterion_image3, train_loader3)\n    average_train_losses.append(average_train_loss)\n    average_test_loss = image_test(epoch, model_image3, criterion_image3, train_loader3)\n\n    # save model with best validation loss\n    if epoch == 1 or average_test_loss < min(average_test_losses):\n        torch.save(model_image3, 'image_classification_model3.pt')\n\n    average_test_losses.append(average_test_loss)\n    \n\n# Plot Training Losses\nplt.plot(average_train_losses)\nplt.title('Train Losses')\nplt.ylabel('Cross Entropy')\nplt.xlabel('Epoch #')\nplt.legend(['Train'], loc='upper right')\nplt.show()\n\n# Plot Testing Losses\nplt.plot(average_test_losses)\nplt.title('Test Losses')\nplt.ylabel('Cross Entropy')\nplt.xlabel('Epoch #')\nplt.legend(['Test'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train and test\n\naverage_train_losses = []\naverage_test_losses = []\n\nfor epoch in range(1, epochs + 1):\n    average_train_loss = image_train(epoch, model_image4, optimizer_image4, criterion_image4, train_loader4)\n    average_train_losses.append(average_train_loss)\n    average_test_loss = image_test(epoch, model_image4, criterion_image4, train_loader4)\n\n    # save model with best validation loss\n    if epoch == 1 or average_test_loss < min(average_test_losses):\n        torch.save(model_image4, 'image_classification_model4.pt')\n\n    average_test_losses.append(average_test_loss)\n    \n\n# Plot Training Losses\nplt.plot(average_train_losses)\nplt.title('Train Losses')\nplt.ylabel('Cross Entropy')\nplt.xlabel('Epoch #')\nplt.legend(['Train'], loc='upper right')\nplt.show()\n\n# Plot Testing Losses\nplt.plot(average_test_losses)\nplt.title('Test Losses')\nplt.ylabel('Cross Entropy')\nplt.xlabel('Epoch #')\nplt.legend(['Test'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 5"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train and test\n\naverage_train_losses = []\naverage_test_losses = []\n\nfor epoch in range(1, epochs + 1):\n    average_train_loss = image_train(epoch, model_image5, optimizer_image5, criterion_image5, train_loader5)\n    average_train_losses.append(average_train_loss)\n    average_test_loss = image_test(epoch, model_image5, criterion_image5, train_loader5)\n\n    # save model with best validation loss\n    if epoch == 1 or average_test_loss < min(average_test_losses):\n        torch.save(model_image5, 'image_classification_model5.pt')\n\n    average_test_losses.append(average_test_loss)\n    \n\n# Plot Training Losses\nplt.plot(average_train_losses)\nplt.title('Train Losses')\nplt.ylabel('Cross Entropy')\nplt.xlabel('Epoch #')\nplt.legend(['Train'], loc='upper right')\nplt.show()\n\n# Plot Testing Losses\nplt.plot(average_test_losses)\nplt.title('Test Losses')\nplt.ylabel('Cross Entropy')\nplt.xlabel('Epoch #')\nplt.legend(['Test'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict Results for Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = torch.load('image_classification_model1.pt')\nmodel1 = model1.to(device)\nmodel1.eval()\n\nmodel2 = torch.load('image_classification_model2.pt')\nmodel2 = model2.to(device)\nmodel2.eval()\n\nmodel3 = torch.load('image_classification_model3.pt')\nmodel3 = model3.to(device)\nmodel3.eval()\n\nmodel4 = torch.load('image_classification_model4.pt')\nmodel4 = model4.to(device)\nmodel4.eval()\n\nmodel5 = torch.load('image_classification_model5.pt')\nmodel5 = model5.to(device)\nmodel5.eval()\n\nresult1 = []\nresult2 = []\n\nfor id in test_df.id.values:\n    img_name = image_path + str(id) + '.jpg'\n    image = Image.open(img_name)\n    \n    tensor_image = preprocess_test(image).unsqueeze(0).to(device)\n    \n    pred1 = model1(tensor_image)\n    pred2 = model2(tensor_image)\n    pred3 = model3(tensor_image)\n    pred4 = model4(tensor_image)\n    pred5 = model5(tensor_image)\n    \n    prediction1 = (nn.Softmax(dim=1)(pred1) + nn.Softmax(dim=1)(pred2) + nn.Softmax(dim=1)(pred3)\n                   + nn.Softmax(dim=1)(pred4) + nn.Softmax(dim=1)(pred5)).argmax(dim=1).item()\n    \n    labels = [pred1.argmax(dim=1).item(), pred2.argmax(dim=1).item(), pred3.argmax(dim=1).item(),\n              pred4.argmax(dim=1).item(), pred5.argmax(dim=1).item()]\n    \n    unique_labels, counts = np.unique(labels, return_counts=True)\n    best_index = np.argmax(counts)\n    prediction2 = unique_labels[best_index]\n    \n    result1.append([id, categories[prediction1]])\n    result2.append([id, categories[prediction2]])\n    \n\nheaders = ['id', 'category']\n\npredict1 = pd.DataFrame(result1, columns=headers)\npredict2 = pd.DataFrame(result2, columns=headers)\n\nprint(predict1)\nprint(predict2)\n\npredict1.to_csv('submission1.csv', index=False)\npredict2.to_csv('submission2.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}